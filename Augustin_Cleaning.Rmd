---
title: "Augustin_Cleaning"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#IMPORT THE DATA

```{r}
getwd()
setwd("/Users/Augustin/Documents/GitHub/DSBA-Group10/WD")

area_data <- read.csv("Community_Statistical_Areas__CSAs___Reference_Boundaries.csv")

cctv_data <- read.csv("Baltimore_CCTV_Locations_Crime_Cameras.csv")

poverty_data <- read.csv("Percent_of_Family_Households_Living_Below_the_Poverty_Line.csv")

crime_data <- read.csv("Baltimore_Part1_Crime_data.csv")

```

#EXPLORE THE DATA

```{r}
#Crime data
View(crime_data)
str(crime_data)
summary(crime_data)
unique(crime_data$Neighborhood)
tolower(crime_data$Neighborhood)

#Area data
View(area_data)

#Poverty data
View(poverty_data)

#CCTV data
View(cctv_data)
```


#DATA MANIPULATIONS


```{r}
library(tidyverse)
library(data.table)
library(sp)
library(rgdal)
library(ggplot2)
```

#Joining of crime dataset and area dataset

```{r}

crime_data <- mutate(crime_data,neigh=tolower(crime_data$Neighborhood)) #Creation of new column with lower case letters

area_data2 <- separate_rows(area_data, Neigh, sep = ", ") #Creation of a new dataset with eigh neighbourhood being assigned to an area

area_data2 <- mutate(area_data2,neigh=tolower(Neigh)) #Creation of new column with lower case letters

crime_data_with_areas <- crime_data %>% 
  left_join(area_data2,by="neigh")

crime_data_NAs <- crime_data %>% 
  anti_join(area_data2,
            by="neigh") #Here is the list of all the NAs we have

unique(crime_data_NAs$neigh) #We see that we have very few unassigned names, we can change this by hand.

crime_data["neigh"][crime_data["neigh"]=="mount washington"] <- "mt. washington"
crime_data["neigh"][crime_data["neigh"]=="carroll - camden industrial area"] <- "caroll-camden industrial area"
crime_data["neigh"][crime_data["neigh"]=="patterson park neighborhood"] <- "patterson park"
crime_data["neigh"][crime_data["neigh"]=="glenham-belhar"] <- "glenham-belford"
crime_data["neigh"][crime_data["neigh"]=="new southwest/mount clare"] <- "hollins market"
crime_data["neigh"][crime_data["neigh"]=="mount winans"] <- "mt. winans"
crime_data["neigh"][crime_data["neigh"]=="rosemont homeowners/tenants"] <- "rosemont"
crime_data["neigh"][crime_data["neigh"]=="broening manor"] <- "o'donnell heights"
crime_data["neigh"][crime_data["neigh"]=="boyd-booth"] <- "booth-boyd"
crime_data["neigh"][crime_data["neigh"]=="lower herring run park"] <- "herring run park"
crime_data["neigh"][crime_data["neigh"]=="mt pleasant park"] <- "mt. pleasant park"

#mount washington = Mt. Washington / carroll - camden industrial area = Caroll-Camden Industrial Area / patterson park neighborhood = Patterson Park / glenham-belhar = Glenham-Belford / new southwest/mount clare = Hollins Market / mount winans = Mt. Winans / rosemont homeowners/tenants = Rosemont / broening manor = O'Donnell Heights / boyd-booth = Booth-boyd / lower herring run park = Herring Run Park / mt pleasant park = Mt. Pleasant Park / We got rid of the 764 remaining observations which had no information about neighbourhood

crime_data_with_areas <- crime_data %>% 
 semi_join(area_data2,by="neigh") %>% 
  left_join(area_data2,by="neigh") #Here we have the final data frame with the community for each crime

str(crime_data_with_areas)

crime_data_with_areas <- crime_data_with_areas[startsWith(as.character(crime_data_with_areas$CrimeDateTime),"20"),] #We have 24 observations that dates back to before the year 2000 and 24 observation with no date


```


#Calculation of the crime rate per community

```{r}
CrimeRatePerArea <- crime_data_with_areas %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea=(n()/nrow(crime_data_with_areas))*100)

CrimeRatePerArea <- rbind(CrimeRatePerArea,list("Unassigned -- Jail",0))

sum(CrimeRatePerArea$CrimeRatePerArea) #The total sum is 100, which is what we expect
```

#Calculation of the density of CCTV per community

```{r}
setwd("/Users/Augustin/Documents/GitHub/DSBA-Group10/WD")

which(is.na(cctv_data$X))
which(is.na(cctv_data$Y))
filter(cctv_data,X=="")
filter(cctv_data,Y=="") #I don't know if it is the proper technique but by doing so I ensure that we have no NAs neihter empty values and so that our dataset is tidy

#read in data table
balt_dat <-  fread("Baltimore_CCTV_Locations_Crime_Cameras.csv")

#convert to data table
balt_dat <- as.data.table(balt_dat)

#make data spatial
coordinates(balt_dat) <-  c("X","Y")
crs.geo1 <-  CRS("+proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs +type=crs")
proj4string(balt_dat) <-  crs.geo1  

plot(balt_dat, pch = 20, col = "steelblue")

#read in shapefile of baltimore
baltimore <-  readOGR(dsn = "./Community_Statistical_Area", layer = "Community_Statistical_Area") #name of file and object
proj4string(baltimore) <- crs.geo1

#plot
plot(baltimore,main="Spread of CCTVs in different communities of Baltimore")
plot(balt_dat,pch=20, col="steelblue" , add=TRUE)

#Perform the count

proj4string(balt_dat)
proj4string(baltimore)

res2 <- over(balt_dat,baltimore)
counts <- table(res2$community)
counts <- as.data.frame(counts)
colnames(counts)[1] <- "Community"
sum(counts$Freq)
```

#Calculate the density for each community

```{r}

CCTV_per_area <- area_data[2] %>% 
  left_join(counts,by="Community") #One must add the communities where there are no counts i.e no CCTV

CCTV_per_area[is.na(CCTV_per_area)] <- 0

CCTV_per_area <- mutate(CCTV_per_area, density_perc=(CCTV_per_area$Freq/(sum(CCTV_per_area$Freq)))*100)

View(CCTV_per_area)
```

#EXPLORATION
#STATISTICS OF CRIME BY TYPES OF CRIME

```{r}
unique(crime_data_with_areas$Description)

#Misdemeanor:LARCENY FROM AUTO,COMMON ASSAULT, ROBBERY - COMMERCIAL, LARCENY
#Felony: RAPE, ARSON, HOMICIDE, BURGLARY, AUTO THEFT, ROBBERY - CARJACKING, AGG. ASSAULT, ROBBERY - STREET, ROBBERY - RESIDENCE, SHOOTING

crime_cat <- data.frame(Category=c("Misdemeanor","Felony"), Description=c(c("LARCENY FROM AUTO,COMMON ASSAULT,ROBBERY - COMMERCIAL,LARCENY"),c("RAPE,ARSON,HOMICIDE,BURGLARY,AUTO THEFT,ROBBERY - CARJACKING,AGG. ASSAULT,ROBBERY - STREET,ROBBERY - RESIDENCE,SHOOTING")))

crime_cat <- separate_rows(crime_cat, Description, sep = ",")

crime_cat$Description %in% unique(crime_data_with_areas$Description) #Ensure we have a perfect match

crime_data_with_areas <- crime_data_with_areas %>% 
  left_join(crime_cat,by="Description") #We had a new varaible to our crime dataset

CrimePerCategoryPerArea <- crime_data_with_areas %>% 
  group_by(Community,Category) %>%
  summarize(RepartitionPerCategoryPerArea=n())

sum(CrimePerCategoryPerArea$RepartitionPerCategoryPerArea)

CrimeCategoryRepartition <- CrimePerCategoryPerArea %>% 
  group_by(Category) %>% 
  summarise(Repartition=sum(RepartitionPerCategoryPerArea)) #We observe that in Baltimore, the number of felony is close to the number of misdemeanor

FelonyStats <-  CrimePerCategoryPerArea %>% filter(Category=="Felony") %>% 
  mutate(FelonyRatePerArea = (RepartitionPerCategoryPerArea/CrimeCategoryRepartition$Repartition[1])*100)

sum(FelonyStats$FelonyRatePerArea)

MisdemeanorStats <-  CrimePerCategoryPerArea %>% filter(Category=="Misdemeanor") %>% 
  mutate(MisdemeanorRatePerArea = (RepartitionPerCategoryPerArea/CrimeCategoryRepartition$Repartition[2])*100)

sum(MisdemeanorStats$MisdemeanorRatePerArea)

```

#CCTV against crimes

```{r}
CCTV_VS_crimes <- CCTV_per_area %>% 
  left_join(CrimeRatePerArea,by="Community")
  
View(CCTV_VS_crimes)

plot(CCTV_VS_crimes$CrimeRatePerArea,CCTV_VS_crimes$density_perc, main="Crime Rate per Community VS CCTV Density per Community",xlab="CrimeRatePerCommunity",ylab="CCTVDensityPerCommunity")

regression <- lm(CCTV_VS_crimes$density_perc~CCTV_VS_crimes$CrimeRatePerArea)
summary(regression)

y<-regression[["coefficients"]][["(Intercept)"]]
x<-regression[["coefficients"]][["CCTV_VS_crimes$CrimeRatePerArea"]]

range <- seq(from=0, to=4.5, by=0.1)

estimation <- x*range+y

lines(range,estimation, col="blue")

#______

plot(FelonyStats$FelonyRatePerArea,CCTV_VS_crimes$density_perc, main="Felony Rate per Community VS CCTV Density per Community",xlab="FelonyRatePerCommunity",ylab="CCTVDensityPerCommunity")

regression5 <- lm(CCTV_VS_crimes$density_perc~FelonyStats$FelonyRatePerArea)
summary(regression5) #There is a very poor correlation 

y5<-regression5[["coefficients"]][["(Intercept)"]]
x5<-regression5[["coefficients"]][["FelonyStats$FelonyRatePerArea"]]

range5 <- seq(from=-1, to=5, by=0.1)

estimation5 <- x5*range5+y5

lines(range5,estimation5, col="blue") 

#______

plot(MisdemeanorStats$MisdemeanorRatePerArea,CCTV_VS_crimes$density_perc, main="Misdemeanor Rate per Community VS CCTV Density per Community",xlab="MisdemeanorRatePerCommunity",ylab="CCTVDensityPerCommunity")

regression6 <- lm(CCTV_VS_crimes$density_perc~MisdemeanorStats$MisdemeanorRatePerArea)
summary(regression6) #There is a very poor correlation 

y6<-regression6[["coefficients"]][["(Intercept)"]]
x6<-regression6[["coefficients"]][["MisdemeanorStats$MisdemeanorRatePerArea"]]

range6 <- seq(from=-1, to=6, by=0.1)

estimation6 <- x6*range6+y6

lines(range6,estimation6, col="blue")

```

#MAPPING OF CRIMES

```{r}
baltimore$community %in% CrimeRatePerArea$Community #We see that we have a perfect match

baltimore@data <- left_join(baltimore@data, CrimeRatePerArea, by = c('community' = 'Community'))

library(tmap)
qtm(baltimore, "CrimeRatePerArea")
```

#MAPPING OF CCTVs

```{r}
baltimore$community %in% CCTV_per_area$Community

baltimore@data <- left_join(baltimore@data, CCTV_per_area, by = c('community' = 'Community'))

qtm(baltimore, "density_perc",fill.title="CCTV Density", fill.style="fixed", fill.breaks=c(0,1,2,3,4,5,6,7,8,9,10,11))

```

#MAPPING OF FELONIES & MAPPING OF MISDEMEANORS 
```{r}

baltimore$community %in% FelonyStats$Community

FelonyStats[56,] <- list("Unassigned -- Jail","Felony",0,0) #The previous line of code allowed to check whether we had a perfect match, so it is not the case, we assign a new value to the only outlier

baltimore@data <- left_join(baltimore@data, FelonyStats, by = c('community' = 'Community'))

library(tmap)
qtm(baltimore, "FelonyRatePerArea", fill.title="Felonies")

baltimore@data[["fid"]]<-baltimore@data[["community"]] #We do that so that we see the name of the Community when using an interactive map

baltimore$community %in% MisdemeanorStats$Community

MisdemeanorStats[56,] <- list("Unassigned -- Jail","Misdemeanor",0,0) #The previous line of code allowed to check whether we had a perfect match, so it is not the case, we assign a new value to the only outlier

baltimore@data <- left_join(baltimore@data, MisdemeanorStats, by = c('community' = 'Community'))

qtm(baltimore, "MisdemeanorRatePerArea", fill.title="Misdemeanor")

plot(FelonyStats$FelonyRatePerArea,MisdemeanorStats$MisdemeanorRatePerArea,main="Felony VS Misdemeanor", xlab="Felony",ylab="Misdemeanor") #This allows us to see whether Felony and Misdemeanors are correlated. This seems to be the case

regression4 <- lm(FelonyStats$FelonyRatePerArea~MisdemeanorStats$MisdemeanorRatePerArea)
summary(regression4)

y4<-regression4[["coefficients"]][["(Intercept)"]]
x4<-regression4[["coefficients"]][["MisdemeanorStats$MisdemeanorRatePerArea"]]

range4 <- seq(from=-1, to=5, by=0.1)

estimation4 <- x4*range4+y4

lines(range4,estimation4, col="blue")

#Still, we see that there seems ot be some outliers. I don't know if it is relevant but the biggest outlier is Downtown/Seton Hill, is turns out it also is one of the richest area in Baltimore.

```

#Comparison of CCTV density vs wealth

```{r}

poverty_data <- rbind(poverty_data,list(56,"Unassigned -- Jail",0,0,0,0,0,0,0))

poverty_data[48,7] <- c(poverty_data[48,3],poverty_data[48,4],poverty_data[48,5],poverty_data[48,6]) %>% mean() #The poverty rate of South Baltimore in 19 was missing. This area's rate over the past years seems to be stable (always one of the richest area), that's why we compute the mean of the past 4 years to replace the missing value.

plot(CCTV_per_area$density_perc,poverty_data$hhpov19, main="CCTV density VS poverty rate",xlab="CCTV Density",ylab="Poverty rate")

regression2 <- lm(poverty_data$hhpov19~CCTV_per_area$density_perc)
summary(regression2)

y2<-regression2[["coefficients"]][["(Intercept)"]]
x2<-regression2[["coefficients"]][["CCTV_per_area$density_perc"]]

range2 <- seq(from=-5, to=12, by=0.2)

estimation2 <- x2*range2+y2

lines(range2,estimation2, col="blue")
```

#Comparison of Crimes VS wealth
```{r}

plot(CrimeRatePerArea$CrimeRatePerArea,poverty_data$hhpov19, main="Crime Rate VS poverty rate",xlab="Crime rate",ylab="Poverty rate")

regression3 <- lm(poverty_data$hhpov19~CrimeRatePerArea$CrimeRatePerArea)
summary(regression3)

y3<-regression3[["coefficients"]][["(Intercept)"]]
x3<-regression3[["coefficients"]][["CrimeRatePerArea$CrimeRatePerArea"]]

range3 <- seq(from=-2, to=4.5, by=0.1)

estimation3 <- x3*range3+y3

lines(range3,estimation3, col="blue")
```

#RESEARCH QUESTION 
Updated Daniel

#ATTEMPT TO MAKE BETTER MAPS
```{r}

Crime_and_CCTV_map <- tm_shape(baltimore) + tm_fill(col = "CrimeRatePerArea", title ="Crime rate per Area in %",style = "quantile") + tm_borders(col="black",alpha=0.3) + tm_layout(inner.margins = 0.05)+ tm_shape(balt_dat) + tm_dots(col="black")

Felony_and_CCTV_map <- tm_shape(baltimore) + tm_fill(col = "FelonyRatePerArea", title ="Felony rate per Area in %", style = "quantile") + tm_borders(col="black",alpha=0.3)+ tm_layout(inner.margins = 0.05) + tm_shape(balt_dat) + tm_dots(col="black")

Misdemeanor_and_CCTV_map <- tm_shape(baltimore) + tm_fill(col = "MisdemeanorRatePerArea", title ="Misdemeanor rate per Area in %",style = "quantile") + tm_borders(col="black",alpha=0.3)+ tm_layout(inner.margins = 0.05) + tm_shape(balt_dat) + tm_dots(col="black")

tmap_arrange(Crime_and_CCTV_map,Felony_and_CCTV_map,Misdemeanor_and_CCTV_map)

sort(baltimore@data[["CrimeRatePerArea"]])

breaks1 <- c(0,0.5,1,1.5,2,2.5,3,3.5,4,4.5) #Not sure what break to use, for the moment I decided to use the automatic break system with the "style" parameter

library(spData)
library(rgeos)

Prison_area <-  st_bbox(c(xmin = -8529169.92, xmax = -8526465.97,
                      ymin =4764196.55, ymax = 4765056.50),
                    crs = st_crs(baltimore)) %>% st_as_sfc()
 
Prison_map <- tm_shape(Prison_area) + tm_borders(col="black",alpha=0.3)+ tm_shape(baltimore) + tm_fill(col = "CrimeRatePerArea", title ="Crime rate per Area in %",style = "quantile") + tm_borders(col="black") + tm_layout(inner.margins = 0.05,frame.lwd = 5,title = "Zoom on Baltimore Prison",title.position = c('left', 'top'))+tm_scale_bar(position = c("left", "top"))+ tm_shape(balt_dat) + tm_dots(col="black") #This map zooms on the prison. This "Area" is special. We have no data on crime there, we can also see that the there is a huge concentration of CCTVs directly next to the prison.


Baltimore_map <- tm_shape(baltimore) + tm_borders()+ tm_shape(test_small_map) + tm_borders(lwd = 3,col = "red") + tm_layout(frame.lwd = 6,inner.margins = 0.05)


Prison_map
print(Baltimore_map, vp = viewport(0.8, 0.27, width = 0.5, height = 0.5)) #By running these two lines together, we obtain 

tmap_mode("plot")
tmap_mode("view") #Use this command to have interacitve maps

library(cartogram)

Distorted_Crime_map <- tm_shape(cartogram_ncont(baltimore, "CrimeRatePerArea"))+tm_fill(col = "CrimeRatePerArea", title ="Crime rate per Area in %",style = "quantile") + tm_borders(col="black",alpha=0.3) + tm_layout(inner.margins = 0.07) #This map distorts the size of each area depending on their respective crime rates. It is interesting as it enables one to see that higher crime rates tends to be concentrated in the city center.



```


