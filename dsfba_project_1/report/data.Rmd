# Data {.tabset}

```{r, echo = FALSE, message = FALSE, warning = FALSE}
source(here::here("scripts/setup.R"))
```

### Data source

We have five raw data sets. All data sets were retrieved on Baltimore government's open data portal. We found data about crimes committed in Baltimore, CCTV location in the city and poverty rates, and the population. We also found a data set showing the reference boundaries of the Community Statistical Area geographies. The latter will certainly be helpful to match each data set's observations together.

### Raw Data sets

### 2.1 Crime Data set

This dataset represents the location and characteristics of major crime against persons such as homicide, shooting, robbery, aggrevated assault etc. within the city of Baltimore. This data set contains 350'294 observations.

   + **RowID** = ID of the row, 350'294 in total
   
   + **CrimeDateTime** = date and time of the crime. Format yyyy/mm/dd hh:mm:sstzd
  
   + **CrimeCode** = Code corresponding to the type of crime committed
  
   + **Location** = Textual information on where the crime was committed 
  
   + **Description** = Textual description of the crime committed corresponding to a CrimeCode.
  
   + **Inside/Outside** = Provides information on whether crime was committed inside or outside
  
   + **Weapon** = Provides details on what weapon has been used, if any

   + **Post** = Number corresponding to the Police Post concerned. A map with corresponding police posts can be found here:
   http://moit.baltimorecity.gov/sites/default/files/police_districts_w_posts.pdf?__cf_chl_captcha_tk__=pmd_NhnE710SS8QEWdKOyT5Ug6IJZGoF6iIntFYY30vctes-1634309136-0-gqNtZGzNAxCjcnBszQPl

   + **District** = Name of the district, regrouping different neighbourhoods. Baltimore is officially divided into nine geographical regions: 
     North, Northeast, East, Southeast, South, Southwest, West, Northwest, and Central.

   + **Neighborhood** = Name of the neighborhood in which the crime was committed. Most names matches with neighborhood names contained in the dataset about       Community Statistical Areas.

   + **Latitude** = Latitude, Coordinate system: EPSG:4326 WGS 84
  
   + **Longitude** = Longitude, Coordinate system: EPSG:4326 WGS 84
    
   + **GeoLocation** = Combination of latitude and longitude, Coordinate system: EPSG:4326 WGS 84
  
   + **Premise** = Information on the premise where the crime was committed. One counts more than 120'000 observations in the streets.
   
```{r}
crime_data <- read.csv(file = here::here("data/Baltimore_Part1_Crime_data.csv"))
```

_Source of the data set:_ [https://data.baltimorecity.gov/datasets/part1-crime-data/explore]

### 2.2 CCTV Data set

This dataset represents closed circuit camera locations capturing activity within 256ft (~2 blocks). It contains 837 observations in total.

  + **X = Longitude:** Coordinate system: EPSG:3857 WGS 84 / Pseudo-Mercator

  + **Y = Latitude:** Coordinate system: EPSG:3857 WGS 84 / Pseudo-Mercator

  + **OBJECTID** = ID of of the camera, 837 in total

  + **CAM_NUM** = Unique number attributed to the camera. This might suggest that the data set does not show the location of every camera in Baltimore.

  + **LOCATION** = Textual information on where the camera is located

  + **PROJ** = Name of the area in which the camera is located. It does not always match the name of the "standard" community statistical areas.

  + **XCCORD** = Longitude, Coordinate system: EPSG:4326 WGS 84

  + **YCOORD** = Latitude, Coordinate system: EPSG:4326 WGS 84

```{r}
cctv_data <- read.csv(file = here::here("data/Baltimore_CCTV_Locations_Crime_Cameras.csv"))
```

_Source of the data set:_ [https://data.baltimorecity.gov/datasets/cctv-locations-crime-cameras/explore]

### 2.3 Poverty Data set

This dataset provides information about the percent of family households living below the poverty line. This indicator measures the percentage of households whose income fell below the poverty threshold out of all households in an area. 

Federal and state governments use such estimates to allocate funds to local communities. Local communities use these estimates to identify the number of individuals or families eligible for various programs. These information will be useful for us to study the dispersion of CCTVs within Baltimore in comparison to the poverty level in a given area.  This dataset contains 55 observations, one percentage for each community statistical area. There seems to only be one NA. The most relevant variables are the following: 

  + **CSA2010** = name of the community statistical area. The Baltimore Data Collaborative and the Baltimore City Department of Planning divided Baltimore into 55 CSAs. These 55 units combine Census Bureau geographies together in ways that match Baltimore’s understanding of community boundaries, and are used in social planning.

  + **hhpov15 - hhpov19** = each these five column contains the percent of Family Households Living Below the Poverty Line for a given year, from 2015 to 2019.

  + **Shape_Area - Shape_Length** = standard fields to determine the area and the perimeter of a polygon

```{r}
poverty_data <- read.csv(file = here::here("data/Percent_of_Family_Households_Living_Below_the_Poverty_Line.csv"))
```

_Source of the data set:_ [https://arcg.is/1qOrnH]

### 2.4 Area Data set

This dataset provides information about the Community Statistical Area geographies for Baltimore City. Based on aggregations of Census tract (2010) geographies. It will serve as a geographical point of reference for us to match each dataset's observations together. This dataset contains 55 observations, one for each of area. The most relevant variables are the following:

  + **community** = name of the community statistical area. The Baltimore Data Collaborative and the Baltimore City Department of Planning divided Baltimore into 55 CSAs. These 55 units combine Census Bureau geographies together in ways that match Baltimore’s understanding of community boundaries, and are used in social planning.

  + **neigh** = name of the neighbourhoods contained in the area. 

  + **tracts** = census tract associated with each neighbourhood. An interactive map of neighborhood statistical areas with census tracts is available            online (http://planning.baltimorecity.gov/sites/default/files/Neighborhood%20Statistical%20Areas%20with%20Census%20Tracts.pdf?__cf_chl_captcha_tk__=pmd_5qD.WnCEfWnEa5h1muEPfTVDhN2uheRFagwmglbtKxg-1634299783-0-gqNtZGzNAzujcnBszQO9).

```{r echo=TRUE}
area_data <- read_csv(file = here::here("data/Community_Statistical_Areas__CSAs___Reference_Boundaries.csv"))
```

_Source of the data set:_ [https://data.baltimorecity.gov/datasets/community-statistical-area-1/explore?location=39.284605%2C-76.620550%2C12.26]

### 2.5 Population Data set

This data set provides information about the population in each Community Statistical Area. Information about the total population in 2010 and 2020 are provided. It will be useful to calculate values per capita in each community.The most relevant variables are the following:

  + **community** = name of the community statistical area. The Baltimore Data Collaborative and the Baltimore City Department of Planning divided Baltimore into 55 CSAs. These 55 units combine Census Bureau geographies together in ways that match Baltimore’s understanding of community boundaries, and are used in social planning.

  + **tpop20** = total population in for each Community Statistical Area in 2020
  
```{r echo=TRUE}
population_data <- read.csv(file = here::here("data/Total_Population.csv"))
```

_Source of the data set:_ [INSERT SOURCE HERE]

### 2.6 Data Wrangling

#### 2.6.1 Data Wrangling: Area

Here, the main goal is the transformation of the area data set into a new data set, which contains one observation per **neighborhood**. Indeed, it is important to distinguish neighborhoods which are smaller areas from communities, which are larger and often contain several neighborhoods. We achieve that by first creating a new data set with each neighborhood being assigned to a community using  `separate_rows` and second establishing a new columns with lower case letter for later merge.To do so, we combine the `mutate` function with  `tolower` which convert the uppercase letters of string to a lowercase string.

```{r echo=TRUE}

area_data2 <- separate_rows(area_data, Neigh, sep = ", ") #Creation of a new data set with each neighborhood being assigned to an area

area_data2 <- mutate(area_data2,neigh=tolower(Neigh)) #Creation of new column with lower case letters

```

#### 2.6.2 Data Wrangling: Crime

As in the crime data set the neighborhood names are written in lower case letters we again create a column with lower case letters to join the two data sets. We join the area data set and the crime data set using `left_join`. Next, we use the `anti_join` function to understand which observation has not matched. The outcome shows all the neighborhoods which did not match. As shown below, the issues mostly come from spelling difference (e.g.: Mount written Mt.). As we have very few observations which do not match, we change the names manually.

  + mount washington $→$ Mt. Washington 
  + carroll - camden industrial area $→$ Caroll-Camden Industrial Area 
  + patterson park neighborhood $→$ Patterson Park 
  + glenham-belhar $→$ Glenham-Belford 
  + new southwest/mount clare $→$ Hollins Market 
  + mount winans $→$ Mt.Winans 
  + rosemont homeowners/tenants $→$ Rosemont 
  + broening manor $→$ O'Donnell Heights 
  + boyd-booth $→$ Booth-boyd 
  + lower herring run park $→$ Herring Run Park 
  + mt pleasant park $→$ Mt. Pleasant Park 
  
```{r}

crime_data <- mutate(crime_data,neigh=tolower(crime_data$Neighborhood)) #Creation of new column with lower case letters

crime_data_with_areas <- crime_data %>% 
  left_join(area_data2,by="neigh") #We create a new data sets that contains the name of the area in which the crime was committed

crime_data_NAs <- crime_data %>% 
  anti_join(area_data2,
            by="neigh") #Here is the list of all the NAs we have

unique(crime_data_NAs$neigh) #We see that we have very few unassigned names, we can change this by hand.

crime_data["neigh"][crime_data["neigh"]=="mount washington"] <- "mt. washington"
crime_data["neigh"][crime_data["neigh"]=="carroll - camden industrial area"] <- "caroll-camden industrial area"
crime_data["neigh"][crime_data["neigh"]=="patterson park neighborhood"] <- "patterson park"
crime_data["neigh"][crime_data["neigh"]=="glenham-belhar"] <- "glenham-belford"
crime_data["neigh"][crime_data["neigh"]=="new southwest/mount clare"] <- "hollins market"
crime_data["neigh"][crime_data["neigh"]=="mount winans"] <- "mt. winans"
crime_data["neigh"][crime_data["neigh"]=="rosemont homeowners/tenants"] <- "rosemont"
crime_data["neigh"][crime_data["neigh"]=="broening manor"] <- "o'donnell heights"
crime_data["neigh"][crime_data["neigh"]=="boyd-booth"] <- "booth-boyd"
crime_data["neigh"][crime_data["neigh"]=="lower herring run park"] <- "herring run park"
crime_data["neigh"][crime_data["neigh"]=="mt pleasant park"] <- "mt. pleasant park"

#We got rid of the 764 remaining observations which had no information about neighbourhood

```
  
We get rid of the 764 remaining observations which had no information about neighborhood. This represent a very tiny portion of our total number of observations. Finally, we use the `semi join` function to create the final data sets which in total is basically the same data set as the original one minus the 764 observations. 

Finally, we want to get rid of the observations dating before 2000, as the the Baltimore CCTV program started in the year 2000. We first check the structure of the data set using the `str` function. We notice that the CrimeDateTime column is not a date. We change that and finally filter the information we want to keep using `filter`.

```{r}

crime_data_with_areas <- crime_data %>% 
 semi_join(area_data2,by="neigh") %>% 
  left_join(area_data2,by="neigh") #Here we have the final data frame with a community for each crime

str(crime_data_with_areas) # We see that the crime CrimeDateTime column is not a date. We thus convert it.

crime_data_with_areas$CrimeDateTime <-  as.Date(crime_data_with_areas$CrimeDateTime)

crime_data_with_areas <- crime_data_with_areas %>%  filter(CrimeDateTime >= as.Date("2000-01-01")) #We had 24 observations that dates back to before the year 2000 and 24 observation with no date. We only select crime committed after 2000 as the CCTV program in Baltimore started in 2000.

```

#### 2.6.3 Data Wrangling: Poverty

56 areas are included in the standard community statistical area system. However, within these 56 statistical areas is also jail included. For the poverty data however, we obviously have only 55 statistical areas provided, since we obviously do not have data about poverty in jail. To solve this inconsistency, we add a new line. Moreover we needed to fill a missing value for Baltimore in the year 2019: Here we took the average of the past years. 

```{r}
poverty_data <- rbind(poverty_data,list(56,"Unassigned -- Jail",0,0,0,0,0,0,0))

poverty_data[48,7] <- c(poverty_data[48,3],poverty_data[48,4],poverty_data[48,5],poverty_data[48,6]) %>% mean() #The poverty rate of South Baltimore in 19 was missing. This area's rate over the past years seems to be stable (always one of the richest area), that's why we compute the mean of the past 4 years to replace the missing value.

```

#### 2.6.4 Data Wrangling: CCTV

This data set seems rather tidy, we will mostly use the first two columns which contain information about the location of each CCTV. Therefore,we still need to make sure to not have any missing values in these two columns. We do so by combination the `which`and the `is.na`function and by filtering for potential empty observations.

```{r results='markup'}

which(is.na(cctv_data$X))
which(is.na(cctv_data$Y))
filter(cctv_data, cctv_data$X=="")
filter(cctv_data, cctv_data$Y=="") 

#We are not sure it is the proper technique but by doing so we ensure that we have no NAs neither empty values and so that our data set is tidy.
```
