# Exploratory data analysis {.tabset}

```{r, echo = FALSE, message = FALSE, warning = FALSE}
source(here::here("scripts/setup.R"))
```

### 3.1 Calculation of the density of CCTV per community

The original CCTV data set which we observed had a slight challenge. Although it contained some neighborhood names, most of them were not matching the "standard neighborhood" names. There, to solve that we involved geospatial counting. 

Our procedure included the following steps. After reading the table and converting the data into a data table, we define what will be the coordinates of the newly created spatial file. Here we have several types of coordinates, we use X and Y which use the EPSG:3857 WGS 84 / Pseudo-Mercator coordinate system. Spatial files must have coordinate systems assigned to them, in the case at hand, we will work with the above mentioned EPSG:3857 WGS 84 / Pseudo-Mercator coordinate system for all the spatial files that we are going to use, therefore, to ensure consistency, we create a crs object called `crs.geo1` that is going to be assigned to all the spatial files we will use. In order to assign a known crs to spatial data, we use the `proj4string` function, to which we assign `crs.geo1`.

```{r echo=TRUE}
#read in data table
balt_dat <-  fread(file = here::here("data/Baltimore_CCTV_Locations_Crime_Cameras.csv"))

#convert to data table
balt_dat <- as.data.table(balt_dat)

#make data spatial
coordinates(balt_dat) <-  c("X","Y")
crs.geo1 <-  CRS("+proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs +type=crs")
proj4string(balt_dat) <-  crs.geo1  
```

Then we plot to see the output (as cloud of points which represent all the CCTVs).

```{r}

plot(balt_dat, pch = 20, col = "steelblue") #We can use the plot function to quickly plot the SpatialPointDataFrame that we created. We see a bunch of points which represent the CCTV location in Baltimore.
```

Next, we have to work with the shapefile which is another special type of file. Basically it is a set of polygons which represent different areas of the city Baltimore. We downloaded this file on the Open Baltimore Portal. We read it in and assign this file again to our crs.geo1 coordinate system. In this way we have assured that our files have the same coordinate system.

```{r echo=TRUE}
#read in shapefile of baltimore
baltimore <-  readOGR(dsn = here::here("data/Community_Statistical_Area"), layer = "Community_Statistical_Area") #name of file and object
proj4string(baltimore) <- crs.geo1
```

We can now plot these two spatial files together to see the spread of CCTVs over the 56 community statistical areas.

```{r echo=TRUE}
#plot
plot(baltimore,main="Spread of CCTVs in different communities of Baltimore")
plot(balt_dat,pch=20, col="steelblue" , add=TRUE) #If we plot these two lines together, what we obtain is a map of baltimore, we have the 56 community statistical areas and the CCTVs on top of the map.
```

To illustrate these results numerically, we need R to count for us how many CCTV belongs to which area. Here, the function `over` counts how many CCTVs are layed over a certain polygon frame. Next, we create a new object called `counts` and  make it into a data frame (so that it is easier for us to work with it). We use  `sum` to ensure that we well and truly have 836 observations which were counted. This is the case so we are happy. Still we notice that we only have 41 rows, meaning there here are only 41 out of 56 areas where there are some CCTV. 

```{r echo=TRUE}
#Perform the count
proj4string(balt_dat)
proj4string(baltimore) #To be able to perform the count, we must ensure that the two spatial files have a similar CRS. This is the case as we attributed these two files "crs.geo1" 

res2 <- over(balt_dat,baltimore) #This function tells you to which community each CCTV belongs to
counts <- table(res2$community)
counts <- as.data.frame(counts)
colnames(counts)[1] <- "Community"
sum(counts$Freq) #We see that we have 836 observation in total, this is a good sign as our initial CCTV data set contained 836 obesrvations
```

To make that workable, we need to create a new CCTV file, from which we just add 0 to each N.A.-location. Lastly, we create a new column with the `mutate` function to calculate the CCTV-density which shows the amount of CCTV per area divided by the total amount of CCTV. 

```{r echo=TRUE}
CCTV_per_area <- area_data[2] %>% 
  left_join(counts,by="Community") #One must add the communities where there are no counts i.e no CCTV

CCTV_per_area[is.na(CCTV_per_area)] <- 0

CCTV_per_area <- mutate(CCTV_per_area, density_perc=(CCTV_per_area$Freq/(sum(CCTV_per_area$Freq)))*100)
```

#### 3.1.1 Mapping of CCTV density

We now want to mape CCTV density on the Baltimore map. We first have to use the piping operator to ensure that the community that we have in the Baltimore data set are the same as the one we are having in the CCTV per are data set. As this only returns true values that means that it works and is good for further analysis. 

```{r}
library(tmap)
baltimore$community %in% CCTV_per_area$Community
```

Next, we perform a `left_join` between the Baltimore shape file and the CCTV per area data set. To hedge against the different writing styles (one time it is written with a capital letter and one time with a small letter), we use the vector in the end. Finally, we create the map with the `tmap` package. The `tmap` package somehow works as the `ggplot2` package: First, we need to define an element, it always starts with the `tm_shape` argument, and then you can add with the plus operator  as many arguments as you wish. We used the Baltimore shape file, filled it with the density percentage, defined some breaks, set the borders and the finally the layout. 

```{r results='markup'}
baltimore@data <- left_join(baltimore@data, CCTV_per_area, by = c('community' = 'Community'))

CCTV_dens_map <- tm_shape(baltimore) + tm_fill(col = "density_perc", title ="CCTV density per Area in %", breaks=c(0,1,2,3,4,5,6,7,8,9,10,11)) + tm_borders(col="black",alpha=0.3) + tm_layout(inner.margins = 0.05)

tmap_mode("plot")
CCTV_dens_map
```

### 3.2 Calculation of the crime rate per community

What we create is the `CrimeRatePerArea`. To achieve that we group the `crime_data_with_areas` data set by community and then use `summarize` which enables us to compute the crime rate per area for each area. Again, we added one more row in the calculations because we have no values for the prison. To make sure we made no mistake, we add up the CrimeRatePerArea column to see whether it equals to 100. This is the case. We can therefore go further confidently.

```{r}
CrimeRatePerArea <- crime_data_with_areas %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea=(n()/nrow(crime_data_with_areas))*100)

CrimeRatePerArea <- rbind(CrimeRatePerArea,list("Unassigned -- Jail",0)) #We have no information about crimes committed in jail, yet, the community statistical area encompass 56 area, including jail. In order to ensure consistency, we must add a 56th observation in this data frame.

sum(CrimeRatePerArea$CrimeRatePerArea) #The total sum is 100, which is what we expect
```

#### 3.2.1 Mapping of crime rates

We want to map  crimes rates per community. The methodology is the same as we did for CCTV density. This time, we use the "quantile" method to create category breaks.

```{r echo=TRUE}
library(tmap)

baltimore$community %in% CrimeRatePerArea$Community #We see that we have a perfect match

baltimore@data <- left_join(baltimore@data, CrimeRatePerArea, by = c('community' = 'Community'))

Crime_map <- tm_shape(baltimore) + tm_fill(col = "CrimeRatePerArea", title ="Crime rate per Area in %",style = "quantile") + tm_borders(col="black",alpha=0.3) + tm_layout(inner.margins = 0.05)

tmap_mode("plot")
Crime_map
```

#### 3.2.2 Creation of a distorted map

To observe crime rates reparatiton in Baltimore visually, we decided to use a distorted map. Again, we use the `tmap` package together with the `cartogram_ncont` function which basically distort the map based on intensity of crime rates in each community. Concretely, we want to show that the crime rate is higher in the city center, comapared to the suburban areas. This can be shown quite neatly graphically. 

```{r}

Distorted_Crime_map <- tm_shape(cartogram_ncont(baltimore, "CrimeRatePerArea"))+tm_fill(col = "CrimeRatePerArea", title ="Crime rate per Area in %",style = "quantile") + tm_borders(col="black",alpha=0.3) + tm_layout(inner.margins = 0.07) #This map distorts the size of each area depending on their respective crime rates. It is interesting as it enables one to see that higher crime rates tends to be concentrated in the city center.

tmap_mode("plot")
Distorted_Crime_map
```

### 3.3 Calculation of crime rates by type of crime

First thing we do here is to compute the unique values of the description column of the crime data set. We see that we have 14 types of crime. We want to observe crimes by types, therefore we want to make new classifications. The law consists of three basic classifications of criminal offenses including **infractions**, **misdemeanors**, and **felonies**. 
In our data set, we have no (?) infractions. The 14 types of crime are divided in this way into the two remaining categories.

  + **Misdemeanor:** LARCENY FROM AUTO,COMMON ASSAULT, ROBBERY - COMMERCIAL, LARCENY
  + **Felony:** RAPE, ARSON, HOMICIDE, BURGLARY, AUTO THEFT, ROBBERY - CARJACKING, AGG. ASSAULT, ROBBERY - STREET, ROBBERY - RESIDENCE, SHOOTING
  
```{r}
unique(crime_data_with_areas$Description)

#We see that we have 14 types of crime. We want to observe crimes by types, therefore we want to make new classifications.The law consists of three basic classifications of criminal offenses including infractions, misdemeanors, and felonies. In our data set, we have infractions.

#Misdemeanor:LARCENY FROM AUTO,COMMON ASSAULT, ROBBERY - COMMERCIAL, LARCENY
#Felony: RAPE, ARSON, HOMICIDE, BURGLARY, AUTO THEFT, ROBBERY - CARJACKING, AGG. ASSAULT, ROBBERY - STREET, ROBBERY - RESIDENCE, SHOOTING
```

Next we create a data set which is called crime_cat and basically tells you which recorded crime type belongs to which crime category. This data set will be used later to make a left joint with the crime_data_per_area. Finally, we are left with the crime data sets with the area datas et with a new column which concerns whether the crime was a felony or a misdemeanor. 

```{r}
crime_cat <- data.frame(Category=c("Misdemeanor","Felony"), Description=c(c("LARCENY FROM AUTO,COMMON ASSAULT,ROBBERY - COMMERCIAL,LARCENY"),c("RAPE,ARSON,HOMICIDE,BURGLARY,AUTO THEFT,ROBBERY - CARJACKING,AGG. ASSAULT,ROBBERY - STREET,ROBBERY - RESIDENCE,SHOOTING")))

crime_cat <- separate_rows(crime_cat, Description, sep = ",")

crime_cat$Description %in% unique(crime_data_with_areas$Description) #Ensure we have a perfect match

crime_data_with_areas <- crime_data_with_areas %>% 
  left_join(crime_cat,by="Description") #We had a new variable to our crime data set
```

Next, we compute the Crime_PerCategory_PerArea. Here we use the piping operator and this time we group by the community and category and obtain the results. Again, we check that we indeed have 349482 observations. Moreover, from that we compute both felony and misdemeanors rates in each community and (again) add the prison line into the newly created data sets.  

```{r echo=TRUE}
CrimePerCategoryPerArea <- crime_data_with_areas %>% 
  group_by(Community,Category) %>%
  summarize(RepartitionPerCategoryPerArea=n())

sum(CrimePerCategoryPerArea$RepartitionPerCategoryPerArea) #Again, we check that we indeed have 349482 observations

CrimeCategoryRepartition <- CrimePerCategoryPerArea %>% 
  group_by(Category) %>% 
  summarise(Repartition=sum(RepartitionPerCategoryPerArea)) #We observe that in Baltimore, the number of felony is close to the number of misdemeanor

FelonyStats <-  CrimePerCategoryPerArea %>% filter(Category=="Felony") %>% 
  mutate(FelonyRatePerArea = (RepartitionPerCategoryPerArea/CrimeCategoryRepartition$Repartition[1])*100)

FelonyStats[56,] <- list("Unassigned -- Jail","Felony",0,0)

MisdemeanorStats <-  CrimePerCategoryPerArea %>% filter(Category=="Misdemeanor") %>% 
  mutate(MisdemeanorRatePerArea = (RepartitionPerCategoryPerArea/CrimeCategoryRepartition$Repartition[2])*100)

MisdemeanorStats[56,] <- list("Unassigned -- Jail","Misdemeanor",0,0)

```

#### 3.3.1 Mapping of felonies and Misdemeanors

After ensuring that we have a perfect match we perform a left joint and for felony and misdemeanor and map everything. 

```{r echo=TRUE}

#Felony

baltimore$community %in% FelonyStats$Community

baltimore@data <- left_join(baltimore@data, FelonyStats, by = c('community' = 'Community'))

Felony_map <- tm_shape(baltimore) + tm_fill(col = "FelonyRatePerArea", title ="Felony rate per Area in %",style = "quantile") + tm_borders(col="black",alpha=0.3) + tm_layout(inner.margins = 0.05)

Felony_map

#Misdemeanor

baltimore$community %in% MisdemeanorStats$Community

baltimore@data <- left_join(baltimore@data, MisdemeanorStats, by = c('community' = 'Community'))

Misdemeanor_map <- tm_shape(baltimore) + tm_fill(col = "MisdemeanorRatePerArea", title ="Misdemeanor rate per Area in %",style = "quantile") + tm_borders(col="black",alpha=0.3) + tm_layout(inner.margins = 0.05)

Misdemeanor_map

```

### 3.4 Calculation of crime evolution

The idea is that we want to get information about how crime evolved. Here we could have done a loop, but could not yet find a way to properly do it. We have created a data set for each year.
The results are interesting. If we compare how many observations we have in each crime-per year datasets, we see that we have ~40.000ish cases a year except from 2020 (which is due to COVID) and the year 2021 (which is not finished. We don't make any datasets for the year 2013 and below, because we see that we have not many observations which date prior to the year 2013.

```{r echo=TRUE}

Crime_in_2021 <- crime_data_with_areas %>%  filter(CrimeDateTime >= as.Date("2021-01-01") & CrimeDateTime <= as.Date("2021-12-31"))

Crime_in_2020 <- crime_data_with_areas %>%  filter(CrimeDateTime >= as.Date("2020-01-01") & CrimeDateTime <= as.Date("2020-12-31"))

Crime_in_2019 <- crime_data_with_areas %>%  filter(CrimeDateTime >= as.Date("2019-01-01") & CrimeDateTime <= as.Date("2019-12-31"))

Crime_in_2018 <- crime_data_with_areas %>%  filter(CrimeDateTime >= as.Date("2018-01-01") & CrimeDateTime <= as.Date("2018-12-31"))

Crime_in_2017 <- crime_data_with_areas %>%  filter(CrimeDateTime >= as.Date("2017-01-01") & CrimeDateTime <= as.Date("2017-12-31"))

Crime_in_2016 <- crime_data_with_areas %>%  filter(CrimeDateTime >= as.Date("2016-01-01") & CrimeDateTime <= as.Date("2016-12-31"))

Crime_in_2015 <- crime_data_with_areas %>%  filter(CrimeDateTime >= as.Date("2015-01-01") & CrimeDateTime <= as.Date("2015-12-31"))

Crime_in_2014 <- crime_data_with_areas %>%  filter(CrimeDateTime >= as.Date("2014-01-01") & CrimeDateTime <= as.Date("2014-12-31"))

crime_data_with_areas %>%  filter(CrimeDateTime < as.Date("2014-01-01")) #We see that we have very few (76) observations before 2014, thus we do not consider them


Crime_Monthly_evolution_map <- crime_data_with_areas %>% 
  count(month=floor_date(CrimeDateTime,"month")) %>% 
  ggplot(aes(month,n))+geom_line()+
  scale_x_date(limits = c(as.Date("2014-01-01"), as.Date("2021-08-31"))) #This enables us to see how crime evolve, month after month

Crime_Monthly_evolution_map

```

Next, we calculate the crime rates for each year with the piping operator, grouping by community and summarize the rates. In the end we create the crime evolution data sets which is a combination of all the data. 

```{r echo=TRUE}
#_____ Calculations of the crime rates

CrimeRatePerArea2021 <- Crime_in_2021 %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea2021=(n()/nrow(Crime_in_2021))*100)

CrimeRatePerArea2021 <- rbind(CrimeRatePerArea2021,list("Unassigned -- Jail",0))

CrimeRatePerArea2020 <- Crime_in_2020 %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea2020=(n()/nrow(Crime_in_2020))*100)

CrimeRatePerArea2020 <- rbind(CrimeRatePerArea2020,list("Unassigned -- Jail",0))

CrimeRatePerArea2019 <- Crime_in_2019 %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea2019=(n()/nrow(Crime_in_2019))*100)

CrimeRatePerArea2019 <- rbind(CrimeRatePerArea2019,list("Unassigned -- Jail",0))

CrimeRatePerArea2018 <- Crime_in_2018 %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea2018=(n()/nrow(Crime_in_2018))*100)

CrimeRatePerArea2018 <- rbind(CrimeRatePerArea2018,list("Unassigned -- Jail",0))

CrimeRatePerArea2017 <- Crime_in_2017 %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea2017=(n()/nrow(Crime_in_2017))*100)

CrimeRatePerArea2017 <- rbind(CrimeRatePerArea2017,list("Unassigned -- Jail",0))

CrimeRatePerArea2016 <- Crime_in_2016 %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea2016=(n()/nrow(Crime_in_2016))*100)

CrimeRatePerArea2016 <- rbind(CrimeRatePerArea2016,list("Unassigned -- Jail",0))

CrimeRatePerArea2015 <- Crime_in_2015 %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea2015=(n()/nrow(Crime_in_2015))*100)

CrimeRatePerArea2015 <- rbind(CrimeRatePerArea2015,list("Unassigned -- Jail",0))

CrimeRatePerArea2014 <- Crime_in_2014 %>% 
  group_by(Community) %>%
  summarize(CrimeRatePerArea2014=(n()/nrow(Crime_in_2014))*100)

CrimeRatePerArea2014 <- rbind(CrimeRatePerArea2014,list("Unassigned -- Jail",0))


crime_evolution <- CrimeRatePerArea2021 %>% 
  left_join(CrimeRatePerArea2020,by="Community") %>% 
  left_join(CrimeRatePerArea2019,by="Community") %>%
  left_join(CrimeRatePerArea2018,by="Community") %>%
  left_join(CrimeRatePerArea2017,by="Community") %>% 
  left_join(CrimeRatePerArea2016,by="Community") %>% 
  left_join(CrimeRatePerArea2015,by="Community") %>% 
  left_join(CrimeRatePerArea2014,by="Community")

```



* Mapping out the underlying structure
* Identifying the most important variables
* Univariate visualizations
* Multivariate visualizations
* Summary tables